{"ast":null,"code":"/** internal\n * class ParserInline\n *\n * Tokenizes paragraph content.\n **/\n'use strict';\n\nvar Ruler = require('./ruler'); ////////////////////////////////////////////////////////////////////////////////\n// Parser rules\n\n\nvar _rules = [['text', require('./rules_inline/text')], ['newline', require('./rules_inline/newline')], ['escape', require('./rules_inline/escape')], ['backticks', require('./rules_inline/backticks')], ['strikethrough', require('./rules_inline/strikethrough').tokenize], ['emphasis', require('./rules_inline/emphasis').tokenize], ['link', require('./rules_inline/link')], ['image', require('./rules_inline/image')], ['autolink', require('./rules_inline/autolink')], ['html_inline', require('./rules_inline/html_inline')], ['entity', require('./rules_inline/entity')]];\nvar _rules2 = [['balance_pairs', require('./rules_inline/balance_pairs')], ['strikethrough', require('./rules_inline/strikethrough').postProcess], ['emphasis', require('./rules_inline/emphasis').postProcess], ['text_collapse', require('./rules_inline/text_collapse')]];\n/**\n * new ParserInline()\n **/\n\nfunction ParserInline() {\n  var i;\n  /**\n   * ParserInline#ruler -> Ruler\n   *\n   * [[Ruler]] instance. Keep configuration of inline rules.\n   **/\n\n  this.ruler = new Ruler();\n\n  for (i = 0; i < _rules.length; i++) {\n    this.ruler.push(_rules[i][0], _rules[i][1]);\n  }\n  /**\n   * ParserInline#ruler2 -> Ruler\n   *\n   * [[Ruler]] instance. Second ruler used for post-processing\n   * (e.g. in emphasis-like rules).\n   **/\n\n\n  this.ruler2 = new Ruler();\n\n  for (i = 0; i < _rules2.length; i++) {\n    this.ruler2.push(_rules2[i][0], _rules2[i][1]);\n  }\n} // Skip single token by running all rules in validation mode;\n// returns `true` if any rule reported success\n//\n\n\nParserInline.prototype.skipToken = function (state) {\n  var ok,\n      i,\n      pos = state.pos,\n      rules = this.ruler.getRules(''),\n      len = rules.length,\n      maxNesting = state.md.options.maxNesting,\n      cache = state.cache;\n\n  if (typeof cache[pos] !== 'undefined') {\n    state.pos = cache[pos];\n    return;\n  }\n\n  if (state.level < maxNesting) {\n    for (i = 0; i < len; i++) {\n      // Increment state.level and decrement it later to limit recursion.\n      // It's harmless to do here, because no tokens are created. But ideally,\n      // we'd need a separate private state variable for this purpose.\n      //\n      state.level++;\n      ok = rules[i](state, true);\n      state.level--;\n\n      if (ok) {\n        break;\n      }\n    }\n  } else {\n    // Too much nesting, just skip until the end of the paragraph.\n    //\n    // NOTE: this will cause links to behave incorrectly in the following case,\n    //       when an amount of `[` is exactly equal to `maxNesting + 1`:\n    //\n    //       [[[[[[[[[[[[[[[[[[[[[foo]()\n    //\n    // TODO: remove this workaround when CM standard will allow nested links\n    //       (we can replace it by preventing links from being parsed in\n    //       validation mode)\n    //\n    state.pos = state.posMax;\n  }\n\n  if (!ok) {\n    state.pos++;\n  }\n\n  cache[pos] = state.pos;\n}; // Generate tokens for input range\n//\n\n\nParserInline.prototype.tokenize = function (state) {\n  var ok,\n      i,\n      rules = this.ruler.getRules(''),\n      len = rules.length,\n      end = state.posMax,\n      maxNesting = state.md.options.maxNesting;\n\n  while (state.pos < end) {\n    // Try all possible rules.\n    // On success, rule should:\n    //\n    // - update `state.pos`\n    // - update `state.tokens`\n    // - return true\n    if (state.level < maxNesting) {\n      for (i = 0; i < len; i++) {\n        ok = rules[i](state, false);\n\n        if (ok) {\n          break;\n        }\n      }\n    }\n\n    if (ok) {\n      if (state.pos >= end) {\n        break;\n      }\n\n      continue;\n    }\n\n    state.pending += state.src[state.pos++];\n  }\n\n  if (state.pending) {\n    state.pushPending();\n  }\n};\n/**\n * ParserInline.parse(str, md, env, outTokens)\n *\n * Process input string and push inline tokens into `outTokens`\n **/\n\n\nParserInline.prototype.parse = function (str, md, env, outTokens) {\n  var i, rules, len;\n  var state = new this.State(str, md, env, outTokens);\n  this.tokenize(state);\n  rules = this.ruler2.getRules('');\n  len = rules.length;\n\n  for (i = 0; i < len; i++) {\n    rules[i](state);\n  }\n};\n\nParserInline.prototype.State = require('./rules_inline/state_inline');\nmodule.exports = ParserInline;","map":{"version":3,"sources":["/Users/yaozixuan/OneDrive/JHU Semester 2/OOSE/my-app/node_modules/markdown-it/lib/parser_inline.js"],"names":["Ruler","require","_rules","tokenize","_rules2","postProcess","ParserInline","i","ruler","length","push","ruler2","prototype","skipToken","state","ok","pos","rules","getRules","len","maxNesting","md","options","cache","level","posMax","end","pending","src","pushPending","parse","str","env","outTokens","State","module","exports"],"mappings":"AAAA;;;;;AAKA;;AAGA,IAAIA,KAAK,GAAaC,OAAO,CAAC,SAAD,CAA7B,C,CAGA;AACA;;;AAEA,IAAIC,MAAM,GAAG,CACX,CAAE,MAAF,EAAqBD,OAAO,CAAC,qBAAD,CAA5B,CADW,EAEX,CAAE,SAAF,EAAqBA,OAAO,CAAC,wBAAD,CAA5B,CAFW,EAGX,CAAE,QAAF,EAAqBA,OAAO,CAAC,uBAAD,CAA5B,CAHW,EAIX,CAAE,WAAF,EAAqBA,OAAO,CAAC,0BAAD,CAA5B,CAJW,EAKX,CAAE,eAAF,EAAqBA,OAAO,CAAC,8BAAD,CAAP,CAAwCE,QAA7D,CALW,EAMX,CAAE,UAAF,EAAqBF,OAAO,CAAC,yBAAD,CAAP,CAAmCE,QAAxD,CANW,EAOX,CAAE,MAAF,EAAqBF,OAAO,CAAC,qBAAD,CAA5B,CAPW,EAQX,CAAE,OAAF,EAAqBA,OAAO,CAAC,sBAAD,CAA5B,CARW,EASX,CAAE,UAAF,EAAqBA,OAAO,CAAC,yBAAD,CAA5B,CATW,EAUX,CAAE,aAAF,EAAqBA,OAAO,CAAC,4BAAD,CAA5B,CAVW,EAWX,CAAE,QAAF,EAAqBA,OAAO,CAAC,uBAAD,CAA5B,CAXW,CAAb;AAcA,IAAIG,OAAO,GAAG,CACZ,CAAE,eAAF,EAAqBH,OAAO,CAAC,8BAAD,CAA5B,CADY,EAEZ,CAAE,eAAF,EAAqBA,OAAO,CAAC,8BAAD,CAAP,CAAwCI,WAA7D,CAFY,EAGZ,CAAE,UAAF,EAAqBJ,OAAO,CAAC,yBAAD,CAAP,CAAmCI,WAAxD,CAHY,EAIZ,CAAE,eAAF,EAAqBJ,OAAO,CAAC,8BAAD,CAA5B,CAJY,CAAd;AAQA;;;;AAGA,SAASK,YAAT,GAAwB;AACtB,MAAIC,CAAJ;AAEA;;;;;;AAKA,OAAKC,KAAL,GAAa,IAAIR,KAAJ,EAAb;;AAEA,OAAKO,CAAC,GAAG,CAAT,EAAYA,CAAC,GAAGL,MAAM,CAACO,MAAvB,EAA+BF,CAAC,EAAhC,EAAoC;AAClC,SAAKC,KAAL,CAAWE,IAAX,CAAgBR,MAAM,CAACK,CAAD,CAAN,CAAU,CAAV,CAAhB,EAA8BL,MAAM,CAACK,CAAD,CAAN,CAAU,CAAV,CAA9B;AACD;AAED;;;;;;;;AAMA,OAAKI,MAAL,GAAc,IAAIX,KAAJ,EAAd;;AAEA,OAAKO,CAAC,GAAG,CAAT,EAAYA,CAAC,GAAGH,OAAO,CAACK,MAAxB,EAAgCF,CAAC,EAAjC,EAAqC;AACnC,SAAKI,MAAL,CAAYD,IAAZ,CAAiBN,OAAO,CAACG,CAAD,CAAP,CAAW,CAAX,CAAjB,EAAgCH,OAAO,CAACG,CAAD,CAAP,CAAW,CAAX,CAAhC;AACD;AACF,C,CAGD;AACA;AACA;;;AACAD,YAAY,CAACM,SAAb,CAAuBC,SAAvB,GAAmC,UAAUC,KAAV,EAAiB;AAClD,MAAIC,EAAJ;AAAA,MAAQR,CAAR;AAAA,MAAWS,GAAG,GAAGF,KAAK,CAACE,GAAvB;AAAA,MACIC,KAAK,GAAG,KAAKT,KAAL,CAAWU,QAAX,CAAoB,EAApB,CADZ;AAAA,MAEIC,GAAG,GAAGF,KAAK,CAACR,MAFhB;AAAA,MAGIW,UAAU,GAAGN,KAAK,CAACO,EAAN,CAASC,OAAT,CAAiBF,UAHlC;AAAA,MAIIG,KAAK,GAAGT,KAAK,CAACS,KAJlB;;AAOA,MAAI,OAAOA,KAAK,CAACP,GAAD,CAAZ,KAAsB,WAA1B,EAAuC;AACrCF,IAAAA,KAAK,CAACE,GAAN,GAAYO,KAAK,CAACP,GAAD,CAAjB;AACA;AACD;;AAED,MAAIF,KAAK,CAACU,KAAN,GAAcJ,UAAlB,EAA8B;AAC5B,SAAKb,CAAC,GAAG,CAAT,EAAYA,CAAC,GAAGY,GAAhB,EAAqBZ,CAAC,EAAtB,EAA0B;AACxB;AACA;AACA;AACA;AACAO,MAAAA,KAAK,CAACU,KAAN;AACAT,MAAAA,EAAE,GAAGE,KAAK,CAACV,CAAD,CAAL,CAASO,KAAT,EAAgB,IAAhB,CAAL;AACAA,MAAAA,KAAK,CAACU,KAAN;;AAEA,UAAIT,EAAJ,EAAQ;AAAE;AAAQ;AACnB;AACF,GAZD,MAYO;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACAD,IAAAA,KAAK,CAACE,GAAN,GAAYF,KAAK,CAACW,MAAlB;AACD;;AAED,MAAI,CAACV,EAAL,EAAS;AAAED,IAAAA,KAAK,CAACE,GAAN;AAAc;;AACzBO,EAAAA,KAAK,CAACP,GAAD,CAAL,GAAaF,KAAK,CAACE,GAAnB;AACD,CA1CD,C,CA6CA;AACA;;;AACAV,YAAY,CAACM,SAAb,CAAuBT,QAAvB,GAAkC,UAAUW,KAAV,EAAiB;AACjD,MAAIC,EAAJ;AAAA,MAAQR,CAAR;AAAA,MACIU,KAAK,GAAG,KAAKT,KAAL,CAAWU,QAAX,CAAoB,EAApB,CADZ;AAAA,MAEIC,GAAG,GAAGF,KAAK,CAACR,MAFhB;AAAA,MAGIiB,GAAG,GAAGZ,KAAK,CAACW,MAHhB;AAAA,MAIIL,UAAU,GAAGN,KAAK,CAACO,EAAN,CAASC,OAAT,CAAiBF,UAJlC;;AAMA,SAAON,KAAK,CAACE,GAAN,GAAYU,GAAnB,EAAwB;AACtB;AACA;AACA;AACA;AACA;AACA;AAEA,QAAIZ,KAAK,CAACU,KAAN,GAAcJ,UAAlB,EAA8B;AAC5B,WAAKb,CAAC,GAAG,CAAT,EAAYA,CAAC,GAAGY,GAAhB,EAAqBZ,CAAC,EAAtB,EAA0B;AACxBQ,QAAAA,EAAE,GAAGE,KAAK,CAACV,CAAD,CAAL,CAASO,KAAT,EAAgB,KAAhB,CAAL;;AACA,YAAIC,EAAJ,EAAQ;AAAE;AAAQ;AACnB;AACF;;AAED,QAAIA,EAAJ,EAAQ;AACN,UAAID,KAAK,CAACE,GAAN,IAAaU,GAAjB,EAAsB;AAAE;AAAQ;;AAChC;AACD;;AAEDZ,IAAAA,KAAK,CAACa,OAAN,IAAiBb,KAAK,CAACc,GAAN,CAAUd,KAAK,CAACE,GAAN,EAAV,CAAjB;AACD;;AAED,MAAIF,KAAK,CAACa,OAAV,EAAmB;AACjBb,IAAAA,KAAK,CAACe,WAAN;AACD;AACF,CAjCD;AAoCA;;;;;;;AAKAvB,YAAY,CAACM,SAAb,CAAuBkB,KAAvB,GAA+B,UAAUC,GAAV,EAAeV,EAAf,EAAmBW,GAAnB,EAAwBC,SAAxB,EAAmC;AAChE,MAAI1B,CAAJ,EAAOU,KAAP,EAAcE,GAAd;AACA,MAAIL,KAAK,GAAG,IAAI,KAAKoB,KAAT,CAAeH,GAAf,EAAoBV,EAApB,EAAwBW,GAAxB,EAA6BC,SAA7B,CAAZ;AAEA,OAAK9B,QAAL,CAAcW,KAAd;AAEAG,EAAAA,KAAK,GAAG,KAAKN,MAAL,CAAYO,QAAZ,CAAqB,EAArB,CAAR;AACAC,EAAAA,GAAG,GAAGF,KAAK,CAACR,MAAZ;;AAEA,OAAKF,CAAC,GAAG,CAAT,EAAYA,CAAC,GAAGY,GAAhB,EAAqBZ,CAAC,EAAtB,EAA0B;AACxBU,IAAAA,KAAK,CAACV,CAAD,CAAL,CAASO,KAAT;AACD;AACF,CAZD;;AAeAR,YAAY,CAACM,SAAb,CAAuBsB,KAAvB,GAA+BjC,OAAO,CAAC,6BAAD,CAAtC;AAGAkC,MAAM,CAACC,OAAP,GAAiB9B,YAAjB","sourcesContent":["/** internal\n * class ParserInline\n *\n * Tokenizes paragraph content.\n **/\n'use strict';\n\n\nvar Ruler           = require('./ruler');\n\n\n////////////////////////////////////////////////////////////////////////////////\n// Parser rules\n\nvar _rules = [\n  [ 'text',            require('./rules_inline/text') ],\n  [ 'newline',         require('./rules_inline/newline') ],\n  [ 'escape',          require('./rules_inline/escape') ],\n  [ 'backticks',       require('./rules_inline/backticks') ],\n  [ 'strikethrough',   require('./rules_inline/strikethrough').tokenize ],\n  [ 'emphasis',        require('./rules_inline/emphasis').tokenize ],\n  [ 'link',            require('./rules_inline/link') ],\n  [ 'image',           require('./rules_inline/image') ],\n  [ 'autolink',        require('./rules_inline/autolink') ],\n  [ 'html_inline',     require('./rules_inline/html_inline') ],\n  [ 'entity',          require('./rules_inline/entity') ]\n];\n\nvar _rules2 = [\n  [ 'balance_pairs',   require('./rules_inline/balance_pairs') ],\n  [ 'strikethrough',   require('./rules_inline/strikethrough').postProcess ],\n  [ 'emphasis',        require('./rules_inline/emphasis').postProcess ],\n  [ 'text_collapse',   require('./rules_inline/text_collapse') ]\n];\n\n\n/**\n * new ParserInline()\n **/\nfunction ParserInline() {\n  var i;\n\n  /**\n   * ParserInline#ruler -> Ruler\n   *\n   * [[Ruler]] instance. Keep configuration of inline rules.\n   **/\n  this.ruler = new Ruler();\n\n  for (i = 0; i < _rules.length; i++) {\n    this.ruler.push(_rules[i][0], _rules[i][1]);\n  }\n\n  /**\n   * ParserInline#ruler2 -> Ruler\n   *\n   * [[Ruler]] instance. Second ruler used for post-processing\n   * (e.g. in emphasis-like rules).\n   **/\n  this.ruler2 = new Ruler();\n\n  for (i = 0; i < _rules2.length; i++) {\n    this.ruler2.push(_rules2[i][0], _rules2[i][1]);\n  }\n}\n\n\n// Skip single token by running all rules in validation mode;\n// returns `true` if any rule reported success\n//\nParserInline.prototype.skipToken = function (state) {\n  var ok, i, pos = state.pos,\n      rules = this.ruler.getRules(''),\n      len = rules.length,\n      maxNesting = state.md.options.maxNesting,\n      cache = state.cache;\n\n\n  if (typeof cache[pos] !== 'undefined') {\n    state.pos = cache[pos];\n    return;\n  }\n\n  if (state.level < maxNesting) {\n    for (i = 0; i < len; i++) {\n      // Increment state.level and decrement it later to limit recursion.\n      // It's harmless to do here, because no tokens are created. But ideally,\n      // we'd need a separate private state variable for this purpose.\n      //\n      state.level++;\n      ok = rules[i](state, true);\n      state.level--;\n\n      if (ok) { break; }\n    }\n  } else {\n    // Too much nesting, just skip until the end of the paragraph.\n    //\n    // NOTE: this will cause links to behave incorrectly in the following case,\n    //       when an amount of `[` is exactly equal to `maxNesting + 1`:\n    //\n    //       [[[[[[[[[[[[[[[[[[[[[foo]()\n    //\n    // TODO: remove this workaround when CM standard will allow nested links\n    //       (we can replace it by preventing links from being parsed in\n    //       validation mode)\n    //\n    state.pos = state.posMax;\n  }\n\n  if (!ok) { state.pos++; }\n  cache[pos] = state.pos;\n};\n\n\n// Generate tokens for input range\n//\nParserInline.prototype.tokenize = function (state) {\n  var ok, i,\n      rules = this.ruler.getRules(''),\n      len = rules.length,\n      end = state.posMax,\n      maxNesting = state.md.options.maxNesting;\n\n  while (state.pos < end) {\n    // Try all possible rules.\n    // On success, rule should:\n    //\n    // - update `state.pos`\n    // - update `state.tokens`\n    // - return true\n\n    if (state.level < maxNesting) {\n      for (i = 0; i < len; i++) {\n        ok = rules[i](state, false);\n        if (ok) { break; }\n      }\n    }\n\n    if (ok) {\n      if (state.pos >= end) { break; }\n      continue;\n    }\n\n    state.pending += state.src[state.pos++];\n  }\n\n  if (state.pending) {\n    state.pushPending();\n  }\n};\n\n\n/**\n * ParserInline.parse(str, md, env, outTokens)\n *\n * Process input string and push inline tokens into `outTokens`\n **/\nParserInline.prototype.parse = function (str, md, env, outTokens) {\n  var i, rules, len;\n  var state = new this.State(str, md, env, outTokens);\n\n  this.tokenize(state);\n\n  rules = this.ruler2.getRules('');\n  len = rules.length;\n\n  for (i = 0; i < len; i++) {\n    rules[i](state);\n  }\n};\n\n\nParserInline.prototype.State = require('./rules_inline/state_inline');\n\n\nmodule.exports = ParserInline;\n"]},"metadata":{},"sourceType":"script"}